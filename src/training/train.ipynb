{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37180881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\vs code\\Project4\\myvenv\\Scripts\\python.exe\n",
      "Version: 2.5.1+cu121\n",
      "Location: D:\\vs code\\Project4\\myvenv\\Lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!pip show torch | findstr \"Location Version\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9567b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version (built with): 12.1\n",
      "GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# check gpu availability and pytorch cuda version\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version (built with):\", torch.version.cuda)\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba8de9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms, models\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report , f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e1d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations \n",
    "class Config:\n",
    "\n",
    "    # Paths \n",
    "    data_dir = Path(\"../Preprocessing/Data/splits\")\n",
    "    model_save_dir = \"models/checkpoints\"\n",
    "    final_model_dir = \"models/final\"\n",
    "    logs_dir = \"logs\"\n",
    "    results_dir = \"results\"\n",
    "\n",
    "    # Model settings \n",
    "    model_name = \"mobilenet_v2\"\n",
    "    num_classes = 7\n",
    "    emotions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "    # Training settings\n",
    "    batch_size = 64\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "    num_epochs_stage1 = 15 # train head only\n",
    "    num_epochs_stage2 = 25 # fine-tune entire model\n",
    "\n",
    "    # image settings \n",
    "    img_size = 224\n",
    "\n",
    "    # training settings \n",
    "    num_workers = 4 # for datalaoder (cpu cores)\n",
    "    mixed_precision = True \n",
    "\n",
    "    # Callbacks \n",
    "    early_stopping_patience = 7\n",
    "    lr_scheduler_patience = 4\n",
    "    lr_scheduler_factor = 0.5\n",
    "\n",
    "    # Device \n",
    "    Device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Random seed \n",
    "    seed = 42\n",
    "\n",
    "def set_seed(seed=42):\n",
    "# Set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887fc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Custom Dataset class \n",
    "class EmotionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, split=\"train\", transform=None):\n",
    "\n",
    "        self.data_dir = Path(data_dir) / split \n",
    "        self.transform = transform \n",
    "        self.emotions = Config.emotions\n",
    "\n",
    "        # Build the list of (image path, label index ) tuples \n",
    "        self.samples = [] \n",
    "        self.labels = []\n",
    "\n",
    "        for label_idx, emotion in enumerate(self.emotions):\n",
    "            emotion_dir = self.data_dir / emotion\n",
    "\n",
    "            if not emotion_dir.exists():\n",
    "                continue\n",
    "\n",
    "            # Get all the images in the emotion directory\n",
    "            image_files = list(emotion_dir.glob(\"*.jpg\")) + list(emotion_dir.glob(\"*.png\"))\n",
    "\n",
    "            for img_path in image_files:\n",
    "                self.samples.append(img_path)\n",
    "                self.labels.append(label_idx)\n",
    "        print(f\"[{split.upper()}] Found {len(self.samples)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \" Return the total number of samples \"\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # get labels \n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label \n",
    "    \n",
    "    def get_class_distribution(self):\n",
    "        \" Returns the distribution of classes in the dataset \"\n",
    "        return np.bincount(self.labels, minlength=Config.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753e7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Augmentation and Transforms\n",
    "def get_transforms(split='train'):\n",
    "    \"\"\"\n",
    "    Define augmentation pipelines\n",
    "    \n",
    "    Train: Aggressive augmentation to prevent overfitting\n",
    "    Val/Test: Only normalization (no randomness!)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ImageNet normalization (pretrained models expect this)\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    \n",
    "    if split == 'train':\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((Config.img_size, Config.img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((Config.img_size, Config.img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2b32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute Class Weights (Handle Imbalnce)\n",
    "\n",
    "def compute_class_weights(dataset):\n",
    "    \"\"\"\n",
    "    Calculate class weights for imbalanced dataset\n",
    "    \n",
    "    Formula: weight = total_samples / (num_classes * samples_per_class)\n",
    "    Higher weight for minority classes\n",
    "    \"\"\"\n",
    "    class_counts = dataset.get_class_distribution()\n",
    "    total_samples = len(dataset)\n",
    "    \n",
    "    weights = total_samples / (Config.num_classes * class_counts)\n",
    "    weights = torch.FloatTensor(weights).to(Config.Device)\n",
    "    \n",
    "    print(\"\\nüìä Class Distribution & Weights:\")\n",
    "    for i, emotion in enumerate(Config.emotions):\n",
    "        print(f\"   {emotion:10s}: {class_counts[i]:4d} samples (weight: {weights[i]:.3f})\")\n",
    "    \n",
    "    return weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6132344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, model_name=Config.model_name, num_classes=Config.num_classes, pretrained=True):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "\n",
    "        # Load pretrained backbone\n",
    "        if model_name == 'mobilenet_v2':\n",
    "            self.backbone = models.mobilenet_v2(pretrained=pretrained)\n",
    "            in_features = self.backbone.classifier[1].in_features\n",
    "            # Remove original classifier\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            \n",
    "        elif model_name == 'efficientnet_b0':\n",
    "            self.backbone = models.efficientnet_b0(pretrained=pretrained)\n",
    "            in_features = self.backbone.classifier[1].in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Model {model_name} not supported\")\n",
    "        \n",
    "\n",
    "        # Custom classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ''' \n",
    "        forward pass \n",
    "        Args:\n",
    "            x: input tensor [batch_size, 3, 224, 224]\n",
    "            returns logits tensor [batch_size, num_classes]\n",
    "            '''\n",
    "        features = self.backbone(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits \n",
    "    \n",
    "    def freeze_backbone(self):\n",
    "        ''' Freeze backbone layers (for stage 1 training)'''\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"üîí Backbone frozen. - training head only\")\n",
    "    \n",
    "    def unfreeze_backbone(self, num_layers=20):\n",
    "        \"\"\"Unfreeze last N layers of backbone (for Stage 2 fine-tuning)\"\"\"\n",
    "        # Get all parameters\n",
    "        params = list(self.backbone.parameters())\n",
    "        \n",
    "        # Unfreeze last num_layers\n",
    "        for param in params[-num_layers:]:\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        frozen = sum(1 for p in self.backbone.parameters() if not p.requires_grad)\n",
    "        trainable = sum(1 for p in self.backbone.parameters() if p.requires_grad)\n",
    "        print(f\"‚úÖ Unfrozen last {num_layers} layers\")\n",
    "        print(f\"   Frozen: {frozen}, Trainable: {trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4f1d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Training Loop\n",
    "class Trainer:\n",
    "    '''\n",
    "    Complete Training pipeline with pytorch\n",
    "    '''\n",
    "    def __init__(self, model, train_loader, val_loader, class_weights, optimizer=None, scheduler=None):\n",
    "        self.model = model.to(Config.Device)\n",
    "        self.train_loader = train_loader \n",
    "        self.val_loader = val_loader \n",
    "\n",
    "        # Loss function with class weights \n",
    "        self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        # Optimizer and scheduler (can be set later)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        # Mixed precision scaler \n",
    "        self.scaler = GradScaler() if Config.mixed_precision else None \n",
    "\n",
    "        # Tracking \n",
    "        self.history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': []\n",
    "        }\n",
    "\n",
    "        self.best_val_acc = 0.0 \n",
    "        self.best_val_loss = float('inf')\n",
    "        self.patience_counter = 0  # FIXED: Was early_stopping_counter\n",
    "    \n",
    "    def set_optimizer(self, optimizer, scheduler=None):\n",
    "        \"\"\"Set or update optimizer and scheduler\"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def train_epoch(self):\n",
    "        ''' Train for one epoch '''\n",
    "        self.model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        pbar = tqdm(self.train_loader, desc=\"Training\")\n",
    "\n",
    "        for images, labels in pbar:\n",
    "            # Move to gpu \n",
    "            images = images.to(Config.Device)\n",
    "            labels = labels.to(Config.Device)\n",
    "\n",
    "            # Zero gradients \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass (with mixed precision if enabled)\n",
    "            if Config.mixed_precision:\n",
    "                with autocast():\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass\n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            # Statistics - FIXED: Changed variable names\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)  # FIXED: was 'total'\n",
    "            correct_preds += (predicted == labels).sum().item()  # FIXED: was 'correct'\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': loss.item(),\n",
    "                'acc': 100. * correct_preds / total_samples  # FIXED: variable names\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / total_samples  # FIXED: was 'total'\n",
    "        epoch_acc = 100. * correct_preds / total_samples  # FIXED: was 'correct/total'\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "\n",
    "        running_loss = 0.0 \n",
    "        correct_preds = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(self.val_loader, desc='Validation'):\n",
    "                images = images.to(Config.Device)\n",
    "                labels = labels.to(Config.Device)\n",
    "\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct_preds += (predicted == labels).sum().item()\n",
    "                \n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = 100. * correct_preds / total_samples\n",
    "\n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def train(self, num_epochs, stage_name='stage1'):\n",
    "        \"\"\"\n",
    "        Complete training loop\n",
    "        \n",
    "        Args:\n",
    "            num_epochs: Number of epochs to train\n",
    "            stage_name: 'stage1' or 'stage2' for checkpoint naming\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üöÄ Starting {stage_name.upper()} Training\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc = self.validate()\n",
    "            \n",
    "            # Scheduler step\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step(val_loss)\n",
    "            \n",
    "            # Save history\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.best_val_loss = val_loss\n",
    "                self.save_checkpoint(f'best_{stage_name}.pth')\n",
    "                print(f\"‚úÖ Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "                self.patience_counter = 0\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.patience_counter >= Config.early_stopping_patience:\n",
    "                print(f\"\\n‚ö†Ô∏è  Early stopping triggered (patience: {Config.early_stopping_patience})\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"‚úÖ {stage_name.upper()} Training Complete!\")\n",
    "        print(f\"   Best Val Acc: {self.best_val_acc:.2f}%\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        Path(Config.model_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'best_val_acc': self.best_val_acc,\n",
    "            'best_val_loss': self.best_val_loss,\n",
    "            'history': self.history,\n",
    "            'config': {\n",
    "                'model_name': Config.model_name,\n",
    "                'num_classes': Config.num_classes,\n",
    "                'emotions': Config.emotions\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        path = Path(Config.model_save_dir) / filename\n",
    "        torch.save(checkpoint, path)\n",
    "    \n",
    "    def load_checkpoint(self, filename):\n",
    "        \"\"\"Load model checkpoint\"\"\"\n",
    "        path = Path(Config.model_save_dir) / filename\n",
    "        checkpoint = torch.load(path)\n",
    "        \n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.best_val_acc = checkpoint['best_val_acc']\n",
    "        self.history = checkpoint['history']\n",
    "        \n",
    "        print(f\"‚úÖ Checkpoint loaded: {filename}\")\n",
    "        print(f\"   Best Val Acc: {self.best_val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "436e6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, save_dir='results'):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation\n",
    "    \n",
    "    Returns:\n",
    "        - Accuracy, Precision, Recall, F1\n",
    "        - Confusion matrix\n",
    "        - Per-class metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"\\nüß™ Evaluating model on test set...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "            images = images.to(Config.Device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Convert to numpy\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Overall accuracy\n",
    "    accuracy = 100. * (all_preds == all_labels).sum() / len(all_labels)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(\n",
    "        all_labels, all_preds,\n",
    "        target_names=Config.emotions,\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"\\nPer-Class Metrics:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for emotion in Config.emotions:\n",
    "        metrics = report[emotion]\n",
    "        print(f\"{emotion:10s} - Precision: {metrics['precision']:.3f} | \"\n",
    "              f\"Recall: {metrics['recall']:.3f} | F1: {metrics['f1-score']:.3f}\")\n",
    "    \n",
    "    # Save confusion matrix plot\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    plot_confusion_matrix(cm, save_path=f\"{save_dir}/confusion_matrix.png\")\n",
    "    \n",
    "    # Save metrics to JSON\n",
    "    with open(f\"{save_dir}/metrics.json\", 'w') as f:\n",
    "        json.dump({\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': report\n",
    "        }, f, indent=4)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Results saved to {save_dir}/\")\n",
    "    \n",
    "    return accuracy, report, cm\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, save_path):\n",
    "    \"\"\"Plot and save confusion matrix\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=Config.emotions,\n",
    "                yticklabels=Config.emotions)\n",
    "    \n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"   Confusion matrix saved: {save_path}\")\n",
    "\n",
    "\n",
    "def plot_training_history(history, save_path='results/training_history.png'):\n",
    "    \"\"\"Plot training curves\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    ax1.plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    ax1.set_title('Loss Over Epochs', fontsize=14)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax2.plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "    ax2.plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "    ax2.set_title('Accuracy Over Epochs', fontsize=14)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"   Training history saved: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ad3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main training pipeline - Two-stage transfer learning\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    set_seed(Config.seed)\n",
    "    Path(Config.model_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(Config.results_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üöÄ EMOTION DETECTION - PyTorch Training Pipeline\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüìç Device: {Config.Device}\")\n",
    "    print(f\"üìç Model: {Config.model_name}\")\n",
    "    print(f\"üìç Batch Size: {Config.batch_size}\")\n",
    "    print(f\"üìç Mixed Precision: {Config.mixed_precision}\")\n",
    "    \n",
    "    # Check GPU\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\nüéÆ GPU Info:\")\n",
    "        print(f\"   Name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LOAD DATA\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìÇ Loading Datasets\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    train_dataset = EmotionDataset(\n",
    "        Config.data_dir, \n",
    "        split='train',\n",
    "        transform=get_transforms('train')\n",
    "    )\n",
    "    \n",
    "    val_dataset = EmotionDataset(\n",
    "        Config.data_dir,\n",
    "        split='val',\n",
    "        transform=get_transforms('val')\n",
    "    )\n",
    "    \n",
    "    test_dataset = EmotionDataset(\n",
    "        Config.data_dir,\n",
    "        split='test',\n",
    "        transform=get_transforms('test')\n",
    "    )\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True  # Faster GPU transfer\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weights(train_dataset)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # BUILD MODEL\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üèóÔ∏è  Building Model\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    model = EmotionClassifier(\n",
    "        model_name=Config.model_name,\n",
    "        num_classes=Config.num_classes,\n",
    "        pretrained=True\n",
    "    )\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "# ========================================================================\n",
    "# STAGE 1: TRAIN HEAD ONLY\n",
    "# ========================================================================\n",
    "\n",
    "    model.freeze_backbone()\n",
    "\n",
    "    # Create trainer WITHOUT optimizer initially\n",
    "    trainer = Trainer(model, train_loader, val_loader, class_weights)\n",
    "\n",
    "    # Setup optimizer for head training\n",
    "    optimizer_stage1 = optim.Adam(\n",
    "        model.classifier.parameters(),\n",
    "        lr=Config.learning_rate,\n",
    "        weight_decay=Config.weight_decay\n",
    "    )\n",
    "\n",
    "    # FIXED: Removed verbose=True (not supported in PyTorch 2.x+)\n",
    "    scheduler_stage1 = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_stage1,\n",
    "        mode='min',\n",
    "        factor=Config.lr_scheduler_factor,\n",
    "        patience=Config.lr_scheduler_patience\n",
    "    )\n",
    "\n",
    "    # Set optimizer and scheduler\n",
    "    trainer.set_optimizer(optimizer_stage1, scheduler_stage1)\n",
    "\n",
    "    # Train stage 1\n",
    "    trainer.train(Config.num_epochs_stage1, stage_name='stage1')\n",
    "\n",
    "    # ========================================================================\n",
    "    # STAGE 2: FINE-TUNING\n",
    "    # ========================================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîì Unfreezing backbone for fine-tuning\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    model.unfreeze_backbone(num_layers=30)\n",
    "\n",
    "    # Setup optimizer for fine-tuning (lower learning rate!)\n",
    "    optimizer_stage2 = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=Config.learning_rate / 10,  # 10x smaller LR\n",
    "        weight_decay=Config.weight_decay\n",
    "    )\n",
    "\n",
    "    # FIXED: Removed verbose=True\n",
    "    scheduler_stage2 = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_stage2,\n",
    "        mode='min',\n",
    "        factor=Config.lr_scheduler_factor,\n",
    "        patience=Config.lr_scheduler_patience\n",
    "    )\n",
    "\n",
    "    # Update optimizer and scheduler for stage 2\n",
    "    trainer.set_optimizer(optimizer_stage2, scheduler_stage2)\n",
    "\n",
    "    # Reset patience counter\n",
    "    trainer.patience_counter = 0\n",
    "\n",
    "    # Train stage 2\n",
    "    trainer.train(Config.num_epochs_stage2, stage_name='stage2')\n",
    "\n",
    "    # ========================================================================\n",
    "    # EVALUATION\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Load best model\n",
    "    best_checkpoint = Path(Config.model_save_dir) / 'best_stage2.pth'\n",
    "    checkpoint = torch.load(best_checkpoint)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy, report, cm = evaluate_model(model, test_loader, Config.results_dir)\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(trainer.history, f\"{Config.results_dir}/training_history.png\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SAVE FINAL MODEL\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üíæ Saving Final Model\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    Path(Config.final_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save full model\n",
    "    final_path = Path(Config.final_model_dir) / 'emotion_model.pth'\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': {\n",
    "            'model_name': Config.model_name,\n",
    "            'num_classes': Config.num_classes,\n",
    "            'emotions': Config.emotions\n",
    "        },\n",
    "        'test_accuracy': accuracy\n",
    "    }, final_path)\n",
    "    \n",
    "    print(f\"‚úÖ Model saved: {final_path}\")\n",
    "    \n",
    "    # Save label mapping\n",
    "    label_map = {i: emotion for i, emotion in enumerate(Config.emotions)}\n",
    "    with open(Path(Config.final_model_dir) / 'label_map.json', 'w') as f:\n",
    "        json.dump(label_map, f, indent=4)\n",
    "    \n",
    "    print(f\"‚úÖ Label map saved: {Config.final_model_dir}/label_map.json\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ TRAINING PIPELINE COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüìä Final Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"üìÅ Results saved in: {Config.results_dir}/\")\n",
    "    print(f\"üíæ Model saved in: {Config.final_model_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad3e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ EMOTION DETECTION - PyTorch Training Pipeline\n",
      "============================================================\n",
      "\n",
      "üìç Device: cuda\n",
      "üìç Model: mobilenet_v2\n",
      "üìç Batch Size: 64\n",
      "üìç Mixed Precision: True\n",
      "\n",
      "üéÆ GPU Info:\n",
      "   Name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "   Memory: 8.59 GB\n",
      "\n",
      "============================================================\n",
      "üìÇ Loading Datasets\n",
      "============================================================\n",
      "\n",
      "[TRAIN] Found 27002 samples.\n",
      "[VAL] Found 5786 samples.\n",
      "[TEST] Found 5787 samples.\n",
      "\n",
      "üìä Class Distribution & Weights:\n",
      "   angry     : 3529 samples (weight: 1.093)\n",
      "   disgust   :  311 samples (weight: 12.403)\n",
      "   fear      : 2868 samples (weight: 1.345)\n",
      "   happy     : 6979 samples (weight: 0.553)\n",
      "   neutral   : 5365 samples (weight: 0.719)\n",
      "   sad       : 5042 samples (weight: 0.765)\n",
      "   surprise  : 2908 samples (weight: 1.326)\n",
      "\n",
      "============================================================\n",
      "üèóÔ∏è  Building Model\n",
      "============================================================\n",
      "\n",
      "Total parameters: 2,585,607\n",
      "Trainable parameters: 2,585,607\n",
      "üîí Backbone frozen. - training head only\n",
      "\n",
      "============================================================\n",
      "üöÄ Starting STAGE1 Training\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40341db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce44a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
