# ğŸ­ Emotion Detection

A deep learning-based emotion detection system that identifies and classifies human emotions from facial expressions using computer vision and neural networks.

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Technologies Used](#technologies-used)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Dataset](#dataset)
- [Model Architecture](#model-architecture)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)

## ğŸ” Overview

This project implements an emotion detection system capable of recognizing various human emotions from facial images. The system uses deep learning techniques to analyze facial features and classify emotions, making it useful for applications in human-computer interaction, mental health monitoring, customer sentiment analysis, and more.

## âœ¨ Features

- **Real-time Emotion Detection**: Detect emotions from live video streams or static images
- **Multiple Emotion Classification**: Classifies emotions into categories (e.g., happy, sad, angry, surprised, neutral, etc.)
- **Pre-trained Models**: Utilizes state-of-the-art deep learning architectures
- **Data Augmentation**: Enhanced training with image augmentation techniques
- **Face Detection**: Automatic face detection using OpenCV
- **Visualization**: Training progress visualization and performance metrics

## ğŸ›  Technologies Used

### Preprocessing & Computer Vision
- **OpenCV**: For face detection and image preprocessing
- **mtcnn**: Face detection and alignment
- **NumPy**: Numerical computations
- **Pillow**: Image processing operations

### Machine Learning & Deep Learning
- **TensorFlow**: Deep learning framework for model training
- **PyTorch**: Alternative deep learning framework
- **torchvision**: Pre-trained models and image transformations
- **scikit-learn**: Machine learning utilities and metrics

### Data Visualization & Analysis
- **Matplotlib**: Plotting and visualization
- **Seaborn**: Statistical data visualization
- **Pandas**: Data manipulation and analysis
- **tqdm**: Progress bars for training loops

## ğŸ“ Project Structure

```
Emotion-Detection/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Preprocessing/
â”‚   â”‚   â””â”€â”€ main.py          # Data preprocessing and face detection
â”‚   â”‚
â”‚   â””â”€â”€ training/
â”‚       â””â”€â”€ train.ipynb      # Model training notebook
â”‚
â”œâ”€â”€ requirements.txt         # Project dependencies
â”œâ”€â”€ .gitignore              # Git ignore file
â””â”€â”€ README.md               # Project documentation
```

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager
- (Optional) CUDA-enabled GPU for faster training

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/MohitRawat017/Emotion-Detection.git
   cd Emotion-Detection
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ’» Usage

### Data Preprocessing

Run the preprocessing script to prepare your dataset:

```bash
python src/Preprocessing/main.py
```

This script will:
- Detect faces in images
- Align and crop faces
- Normalize pixel values
- Apply data augmentation
- Save processed images

### Model Training

Open and run the training notebook:

```bash
jupyter notebook src/training/train.ipynb
```

The notebook includes:
- Data loading and exploration
- Model architecture definition
- Training loop with validation
- Performance evaluation
- Model checkpointing

### Inference

```python
import cv2
import torch
from model import EmotionDetector

# Load trained model
model = EmotionDetector()
model.load_state_dict(torch.load('model_checkpoint.pth'))
model.eval()

# Detect emotion from image
image = cv2.imread('test_image.jpg')
emotion = model.predict(image)
print(f"Detected emotion: {emotion}")
```

## ğŸ“Š Dataset

This project can be trained on various emotion detection datasets:

- **FER2013**: Facial Expression Recognition 2013 dataset
- **CK+**: Extended Cohn-Kanade dataset
- **AffectNet**: Large-scale facial expression dataset
- **RAF-DB**: Real-world Affective Faces Database

### Data Format

Ensure your dataset follows this structure:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ angry/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ sad/
â”‚   â”œâ”€â”€ surprised/
â”‚   â””â”€â”€ neutral/
â””â”€â”€ test/
    â”œâ”€â”€ angry/
    â”œâ”€â”€ happy/
    â”œâ”€â”€ sad/
    â”œâ”€â”€ surprised/
    â””â”€â”€ neutral/
```

## ğŸ— Model Architecture

The project implements several architectures:

1. **Custom CNN**: Convolutional Neural Network designed for emotion classification
2. **ResNet**: Residual Network for deeper feature extraction
3. **VGG**: VGG-based architecture for robust performance
4. **Transfer Learning**: Fine-tuning pre-trained models

### Key Components:
- Convolutional layers for feature extraction
- Batch normalization for training stability
- Dropout for regularization
- Fully connected layers for classification
- Softmax activation for emotion probabilities

## ğŸ“ˆ Results

*Training results and performance metrics will be updated after model training.*

### Performance Metrics
- **Accuracy**: TBD
- **Precision**: TBD
- **Recall**: TBD
- **F1-Score**: TBD

### Confusion Matrix
*Confusion matrix visualization will be added here*

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a new branch (`git checkout -b feature/improvement`)
3. Make your changes
4. Commit your changes (`git commit -am 'Add new feature'`)
5. Push to the branch (`git push origin feature/improvement`)
6. Create a Pull Request

### Areas for Contribution
- [ ] Add more emotion categories
- [ ] Implement real-time video detection
- [ ] Optimize model performance
- [ ] Add web interface
- [ ] Improve documentation
- [ ] Add unit tests

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Contact

**Mohit Rawat**

- GitHub: [@MohitRawat017](https://github.com/MohitRawat017)
- Project Link: [https://github.com/MohitRawat017/Emotion-Detection](https://github.com/MohitRawat017/Emotion-Detection)

## ğŸ™ Acknowledgments

- Thanks to the creators of the datasets used in this project
- Inspired by research in affective computing and emotion recognition
- Built with powerful deep learning frameworks

## ğŸ“š References

1. Goodfellow, I. J., et al. "Challenges in representation learning: A report on three machine learning contests." Neural Networks (2013).
2. Mollahosseini, A., et al. "AffectNet: A database for facial expression, valence, and arousal computing in the wild." IEEE TAC (2017).

---

â­ Star this repository if you find it helpful!

ğŸ› Found a bug? [Open an issue](https://github.com/MohitRawat017/Emotion-Detection/issues)

ğŸ’¡ Have a suggestion? [Start a discussion](https://github.com/MohitRawat017/Emotion-Detection/discussions)
